{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4a13ab",
   "metadata": {},
   "source": [
    "# Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81399b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9730f6",
   "metadata": {},
   "source": [
    "# Import the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6587909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_reviews = pd.read_csv('imdb_reviews.csv')\n",
    "test_reviews = pd.read_csv('test_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b23a1d48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;START this film was just brilliant casting lo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;START big hair big boobs bad music and a gian...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;START this has to be one of the worst films o...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;START the &lt;UNK&gt; &lt;UNK&gt; at storytelling the tra...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;START worst mistake of my life br br i picked...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews Sentiment\n",
       "0  <START this film was just brilliant casting lo...  positive\n",
       "1  <START big hair big boobs bad music and a gian...  negative\n",
       "2  <START this has to be one of the worst films o...  negative\n",
       "3  <START the <UNK> <UNK> at storytelling the tra...  positive\n",
       "4  <START worst mistake of my life br br i picked...  negative"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cfc2ef",
   "metadata": {},
   "source": [
    "# Import the Word Index File\n",
    "\n",
    "This file was used in this project for converting words to the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e50133d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = pd.read_csv('word_indexes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ab2b3314",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tsukino</td>\n",
       "      <td>52009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nunnery</td>\n",
       "      <td>52010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sonja</td>\n",
       "      <td>16819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vani</td>\n",
       "      <td>63954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>woods</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Words  Indexes\n",
       "0  tsukino    52009\n",
       "1  nunnery    52010\n",
       "2    sonja    16819\n",
       "3     vani    63954\n",
       "4    woods     1411"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ec5ba",
   "metadata": {},
   "source": [
    "## Convert the word index to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "076b3ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = dict(zip(word_index.Words, word_index.Indexes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ca55e2",
   "metadata": {},
   "source": [
    "## Add some words in the Word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cca172b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START\"]=1\n",
    "word_index[\"<UNK>\"] = 2\n",
    "word_index[\"<UNUSED>\"]=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f166de7",
   "metadata": {},
   "source": [
    "## Function for converting the words to the numbers which was identified in the Word Index file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "95e1f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_encoder(text):\n",
    "    arr = [word_index[word] for word in text]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3811fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels=imdb_reviews['Reviews'], imdb_reviews['Sentiment']\n",
    "test_data, test_labels=test_reviews['Reviews'], test_reviews['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d88068a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <START this film was just brilliant casting lo...\n",
       "1    <START big hair big boobs bad music and a gian...\n",
       "2    <START this has to be one of the worst films o...\n",
       "3    <START the <UNK> <UNK> at storytelling the tra...\n",
       "4    <START worst mistake of my life br br i picked...\n",
       "Name: Reviews, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9c6c84",
   "metadata": {},
   "source": [
    "## Split the sentences into the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9a35381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.apply(lambda review:review.split())\n",
    "test_data = test_data.apply(lambda review:review.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ee87dc",
   "metadata": {},
   "source": [
    "## Convert words in the train data to the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ba02952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.apply(review_encoder)\n",
    "test_data = test_data.apply(review_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bde14e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a810c2",
   "metadata": {},
   "source": [
    "## Transform the Sentiment column to the numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8375f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentiments(sentiment):\n",
    "    if(sentiment == 'positive'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "292ca919",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.apply(encode_sentiments)\n",
    "test_labels = test_labels.apply(encode_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9779f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=word_index[\"<PAD>\"], padding='post', maxlen = 500)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=word_index[\"<PAD>\"], padding='post', maxlen = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804e7b6b",
   "metadata": {},
   "source": [
    "# Build the Model\n",
    "\n",
    "I added one hidden layer. I used ReLu activation function in the hidden layer and Sigmoid activation function in the output layer. I also used Adam optimizer function and Binary crossentropy for loss and accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cef23502",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Embedding(10000,16, input_length=500),\n",
    "                        keras.layers.GlobalAveragePooling1D(),\n",
    "                        keras.layers.Dense(16, activation='relu'),\n",
    "                        keras.layers.Dense(1,activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3461a4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss= 'binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "208746b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "49/49 [==============================] - 3s 49ms/step - loss: 0.6919 - accuracy: 0.5500 - val_loss: 0.6899 - val_accuracy: 0.6936\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.6844 - accuracy: 0.7007 - val_loss: 0.6776 - val_accuracy: 0.7048\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.6625 - accuracy: 0.7202 - val_loss: 0.6478 - val_accuracy: 0.7436\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.6190 - accuracy: 0.7839 - val_loss: 0.5987 - val_accuracy: 0.7858\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.5590 - accuracy: 0.8098 - val_loss: 0.5403 - val_accuracy: 0.8060\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.4937 - accuracy: 0.8356 - val_loss: 0.4830 - val_accuracy: 0.8300\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.4354 - accuracy: 0.8569 - val_loss: 0.4361 - val_accuracy: 0.8444\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.3882 - accuracy: 0.8701 - val_loss: 0.4000 - val_accuracy: 0.8546\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.3511 - accuracy: 0.8808 - val_loss: 0.3727 - val_accuracy: 0.8616\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.3233 - accuracy: 0.8898 - val_loss: 0.3533 - val_accuracy: 0.8665\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2999 - accuracy: 0.8958 - val_loss: 0.3378 - val_accuracy: 0.8708\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.2809 - accuracy: 0.9020 - val_loss: 0.3261 - val_accuracy: 0.8731\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.2655 - accuracy: 0.9071 - val_loss: 0.3166 - val_accuracy: 0.8759\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.2517 - accuracy: 0.9120 - val_loss: 0.3094 - val_accuracy: 0.8773\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.2395 - accuracy: 0.9167 - val_loss: 0.3025 - val_accuracy: 0.8808\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.2300 - accuracy: 0.9196 - val_loss: 0.2976 - val_accuracy: 0.8819\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.2191 - accuracy: 0.9237 - val_loss: 0.2946 - val_accuracy: 0.8823\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.2110 - accuracy: 0.9267 - val_loss: 0.2915 - val_accuracy: 0.8848\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2021 - accuracy: 0.9305 - val_loss: 0.2907 - val_accuracy: 0.8839\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.1951 - accuracy: 0.9327 - val_loss: 0.2879 - val_accuracy: 0.8851\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.1881 - accuracy: 0.9349 - val_loss: 0.2872 - val_accuracy: 0.8856\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.1818 - accuracy: 0.9383 - val_loss: 0.2872 - val_accuracy: 0.8855\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.1761 - accuracy: 0.9398 - val_loss: 0.2857 - val_accuracy: 0.8861\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.1700 - accuracy: 0.9422 - val_loss: 0.2852 - val_accuracy: 0.8866\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.1646 - accuracy: 0.9448 - val_loss: 0.2857 - val_accuracy: 0.8862\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.1598 - accuracy: 0.9474 - val_loss: 0.2872 - val_accuracy: 0.8858\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.1558 - accuracy: 0.9475 - val_loss: 0.2881 - val_accuracy: 0.8860\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.1504 - accuracy: 0.9502 - val_loss: 0.2906 - val_accuracy: 0.8851\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.1463 - accuracy: 0.9513 - val_loss: 0.2922 - val_accuracy: 0.8850\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.1422 - accuracy: 0.9530 - val_loss: 0.2958 - val_accuracy: 0.8851\n"
     ]
    }
   ],
   "source": [
    "history_model = model.fit(train_data,train_labels,epochs = 30, batch_size=512, validation_data= [test_data,test_labels] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c14c95",
   "metadata": {},
   "source": [
    "# Interpretation of the training results\n",
    "\n",
    "My model accuracy is .95 and validation score is .88 so I can say that my model can predict thhe result as true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db73e11",
   "metadata": {},
   "source": [
    "# Build a new model\n",
    "\n",
    "I want to try a new model. In this model, I used Batch Normalization and Dropout and I added a new hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4c44bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential([keras.layers.Embedding(10000,32, input_length=500),\n",
    "                        keras.layers.GlobalAveragePooling1D(),\n",
    "                        keras.layers.Dense(16, activation='relu'),\n",
    "                        keras.layers.BatchNormalization(),\n",
    "                        keras.layers.Dropout(0.5),\n",
    "                        keras.layers.Dense(8, activation='relu'),\n",
    "                        keras.layers.Dense(1,activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "85d4ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', loss= 'binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "964c937c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "49/49 [==============================] - 5s 78ms/step - loss: 0.6537 - accuracy: 0.6508 - val_loss: 0.6843 - val_accuracy: 0.7902\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 4s 77ms/step - loss: 0.4689 - accuracy: 0.8401 - val_loss: 0.6484 - val_accuracy: 0.7784\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 4s 75ms/step - loss: 0.3077 - accuracy: 0.8938 - val_loss: 0.5968 - val_accuracy: 0.8192\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 3s 68ms/step - loss: 0.2346 - accuracy: 0.9187 - val_loss: 0.5515 - val_accuracy: 0.7617\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 3s 69ms/step - loss: 0.1949 - accuracy: 0.9342 - val_loss: 0.5084 - val_accuracy: 0.7534\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 3s 70ms/step - loss: 0.1605 - accuracy: 0.9484 - val_loss: 0.4634 - val_accuracy: 0.7784\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 4s 79ms/step - loss: 0.1453 - accuracy: 0.9516 - val_loss: 0.4383 - val_accuracy: 0.7786\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 3s 70ms/step - loss: 0.1225 - accuracy: 0.9629 - val_loss: 0.3496 - val_accuracy: 0.8649\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 3s 69ms/step - loss: 0.1063 - accuracy: 0.9700 - val_loss: 0.3854 - val_accuracy: 0.8209\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 3s 69ms/step - loss: 0.0912 - accuracy: 0.9737 - val_loss: 0.3709 - val_accuracy: 0.8401\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 4s 73ms/step - loss: 0.0823 - accuracy: 0.9766 - val_loss: 0.3489 - val_accuracy: 0.8624\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 4s 74ms/step - loss: 0.0702 - accuracy: 0.9810 - val_loss: 0.4020 - val_accuracy: 0.8598\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 3s 70ms/step - loss: 0.0659 - accuracy: 0.9813 - val_loss: 0.4871 - val_accuracy: 0.8428\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 3s 69ms/step - loss: 0.0598 - accuracy: 0.9836 - val_loss: 0.5390 - val_accuracy: 0.8537\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 3s 70ms/step - loss: 0.0568 - accuracy: 0.9824 - val_loss: 0.7834 - val_accuracy: 0.8239\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 4s 72ms/step - loss: 0.0480 - accuracy: 0.9857 - val_loss: 0.6879 - val_accuracy: 0.8501\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 4s 73ms/step - loss: 0.0444 - accuracy: 0.9880 - val_loss: 1.4054 - val_accuracy: 0.7416\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 3s 69ms/step - loss: 0.0488 - accuracy: 0.9850 - val_loss: 0.7909 - val_accuracy: 0.8484\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 3s 69ms/step - loss: 0.0373 - accuracy: 0.9891 - val_loss: 0.8619 - val_accuracy: 0.8445\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 3s 71ms/step - loss: 0.0524 - accuracy: 0.9821 - val_loss: 0.8977 - val_accuracy: 0.8382\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 4s 74ms/step - loss: 0.0426 - accuracy: 0.9862 - val_loss: 1.2001 - val_accuracy: 0.7918\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 3s 69ms/step - loss: 0.0338 - accuracy: 0.9899 - val_loss: 0.9444 - val_accuracy: 0.8458\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 3s 70ms/step - loss: 0.0298 - accuracy: 0.9915 - val_loss: 1.1098 - val_accuracy: 0.8229\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 4s 73ms/step - loss: 0.0233 - accuracy: 0.9936 - val_loss: 1.0455 - val_accuracy: 0.8303\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 4s 76ms/step - loss: 0.0241 - accuracy: 0.9935 - val_loss: 1.0508 - val_accuracy: 0.8419\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 4s 76ms/step - loss: 0.0244 - accuracy: 0.9922 - val_loss: 1.1492 - val_accuracy: 0.8374\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 3s 72ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 1.1499 - val_accuracy: 0.8398\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 3s 68ms/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 1.1977 - val_accuracy: 0.8400\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 4s 76ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 1.1972 - val_accuracy: 0.8407\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 4s 77ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 1.2783 - val_accuracy: 0.8395\n"
     ]
    }
   ],
   "source": [
    "history_model = model2.fit(train_data,train_labels,epochs = 30, batch_size=512, validation_data= [test_data,test_labels] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d35d3e0",
   "metadata": {},
   "source": [
    "# Interpretation of the new model\n",
    "\n",
    "My new model has .99 accuracy but .83 validation accuracy so I should say that my model was over-fitting. So, this is not good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceb19bf",
   "metadata": {},
   "source": [
    "# Build a new one\n",
    "\n",
    "This time, I just used a hidden layer with more perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2a6d19c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.Sequential([keras.layers.Embedding(10000,32, input_length=500),\n",
    "                        keras.layers.GlobalAveragePooling1D(),\n",
    "                        keras.layers.Dense(32, activation='relu'),\n",
    "                        keras.layers.Dense(16, activation='relu'),\n",
    "                        keras.layers.Dense(1,activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a4a76aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam', loss= 'binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dbaee039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "49/49 [==============================] - 4s 73ms/step - loss: 0.6908 - accuracy: 0.5390 - val_loss: 0.6857 - val_accuracy: 0.7020\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 4s 74ms/step - loss: 0.6622 - accuracy: 0.7060 - val_loss: 0.6266 - val_accuracy: 0.7160\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 4s 73ms/step - loss: 0.5481 - accuracy: 0.8051 - val_loss: 0.4793 - val_accuracy: 0.8257\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 3s 72ms/step - loss: 0.3895 - accuracy: 0.8666 - val_loss: 0.3651 - val_accuracy: 0.8612\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 4s 72ms/step - loss: 0.2964 - accuracy: 0.8930 - val_loss: 0.3194 - val_accuracy: 0.8737\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 4s 75ms/step - loss: 0.2499 - accuracy: 0.9086 - val_loss: 0.2986 - val_accuracy: 0.8809\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 4s 76ms/step - loss: 0.2192 - accuracy: 0.9200 - val_loss: 0.2887 - val_accuracy: 0.8844\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 3s 70ms/step - loss: 0.1952 - accuracy: 0.9308 - val_loss: 0.2871 - val_accuracy: 0.8848\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 3s 70ms/step - loss: 0.1776 - accuracy: 0.9374 - val_loss: 0.2886 - val_accuracy: 0.8854\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 3s 71ms/step - loss: 0.1618 - accuracy: 0.9435 - val_loss: 0.2914 - val_accuracy: 0.8860\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 4s 81ms/step - loss: 0.1487 - accuracy: 0.9495 - val_loss: 0.2962 - val_accuracy: 0.8870\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 4s 72ms/step - loss: 0.1377 - accuracy: 0.9534 - val_loss: 0.3041 - val_accuracy: 0.8863\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 3s 70ms/step - loss: 0.1290 - accuracy: 0.9566 - val_loss: 0.3188 - val_accuracy: 0.8810\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 3s 71ms/step - loss: 0.1211 - accuracy: 0.9596 - val_loss: 0.3235 - val_accuracy: 0.8824\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 4s 73ms/step - loss: 0.1120 - accuracy: 0.9640 - val_loss: 0.3359 - val_accuracy: 0.8796\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 4s 74ms/step - loss: 0.1042 - accuracy: 0.9678 - val_loss: 0.3456 - val_accuracy: 0.8795\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 3s 70ms/step - loss: 0.0959 - accuracy: 0.9712 - val_loss: 0.3709 - val_accuracy: 0.8719\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 3s 70ms/step - loss: 0.0901 - accuracy: 0.9730 - val_loss: 0.3721 - val_accuracy: 0.8754\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 3s 70ms/step - loss: 0.0837 - accuracy: 0.9758 - val_loss: 0.3871 - val_accuracy: 0.8740\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 4s 73ms/step - loss: 0.0784 - accuracy: 0.9781 - val_loss: 0.4026 - val_accuracy: 0.8710\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 4s 73ms/step - loss: 0.0767 - accuracy: 0.9781 - val_loss: 0.4162 - val_accuracy: 0.8699\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 3s 70ms/step - loss: 0.0688 - accuracy: 0.9818 - val_loss: 0.4292 - val_accuracy: 0.8690\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 4s 79ms/step - loss: 0.0628 - accuracy: 0.9845 - val_loss: 0.4446 - val_accuracy: 0.8677\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 4s 81ms/step - loss: 0.0594 - accuracy: 0.9861 - val_loss: 0.4718 - val_accuracy: 0.8616\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 4s 82ms/step - loss: 0.0558 - accuracy: 0.9868 - val_loss: 0.4761 - val_accuracy: 0.8662\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 4s 81ms/step - loss: 0.0517 - accuracy: 0.9884 - val_loss: 0.4904 - val_accuracy: 0.8656\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 4s 79ms/step - loss: 0.0503 - accuracy: 0.9881 - val_loss: 0.5089 - val_accuracy: 0.8645\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 4s 82ms/step - loss: 0.0446 - accuracy: 0.9907 - val_loss: 0.5235 - val_accuracy: 0.8635\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 4s 84ms/step - loss: 0.0434 - accuracy: 0.9909 - val_loss: 0.5509 - val_accuracy: 0.8617\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 4s 74ms/step - loss: 0.0397 - accuracy: 0.9924 - val_loss: 0.5574 - val_accuracy: 0.8594\n"
     ]
    }
   ],
   "source": [
    "history_model = model3.fit(train_data,train_labels,epochs = 30, batch_size=512, validation_data= [test_data,test_labels] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad06de",
   "metadata": {},
   "source": [
    "# Interpretation of the result:\n",
    "\n",
    "The result is the same as before model. My model accuracy is .99 however validation accuracy is .85. So my model is over-fitting again. All in all, the first is first :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2191f5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
